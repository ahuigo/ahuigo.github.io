---
date: 2018-08-23
title: 关于直播的P2P架构
---
# 关于直播的P2P架构
现在的直播大多都是中心化的CDN 架构，首先是主播RTMP 推流到CDN 服务器，然后用户从通过次级CDN 链路拉流。

这种架构最成熟稳定，但是成本巨大。直播本身和聊天一样都是属于点对点通信。
如果能用点对点做直播，那么不仅节省一堆服务器成本，还能解决大量的带宽问题。

[h5p2p] 总结了几种P2P 的架构:
1. Tree：树型
2. Mesh：网状
3. PCDN

## 树形P2P 分级架构
架构简化图 来自于[h5p2p]：
![](/img/course/im-live-p2p-framework.png)

这种架构的缺点是:
1. 当播放人数变多，直播的节点层级也变得很大，导致它的延时非常大
2. 节点很容易出现退出等不稳定情况
3. 用户的上行带宽不足

## 网状P2P 架构
这种架构解决了节点不稳定问题: 数据流一到播放节点，直接就开始在节点之间互相传输。(题图[h5p2p])
![](/img/im/live-p2p-framework-net.png)

用 WebRTC 来做 P2P 的 Peer5 采用的是网状 P2P 网络。Streamroot 的解决方案也是网状结构。
- 但是多层级延迟问题还是没有解决
- 用户的上行带宽不足: 比如推流的码率是2M, 上行却只有2M, 不能构成树形分支

## PCDN
基于P2P的缺点:
1. 带宽不够，节点分享率低. 我们用CDN 节点+第三方节点补充啊
2. 多层级延迟大. 我们使用平铺的结构啊

有人考虑到P2P+CDN 结合为PCDN. 参考又拍云的架构

![](/img/im/live-p2p-pcdn.png)

PCDN 的优化: 
1. 增加大量的第三方设备数量: 提高上行带宽供应量，降低CDN节点压力，从而提高节点分享比例. 不存在P2P “只有播放者，才是供应者”的局限。
2. 动态调参：流畅性、高分享率是矛盾的。提高分享率会占用带宽，降低流畅性。这两个指标需要动态平衡。

## Reference
- [h5p2p]

[h5p2p]: https://segmentfault.com/a/1190000015195994