---
title: 数据库CAP 理论 与事务
date: 2018-09-27
---
# CAP定理（CAP theorem）
CAP定理（CAP theorem), 指出对于一个分布式计算系统来说，不可能同时满足以下三点:

1. 一致性(Consistency) (所有节点在同一时间具有相同的数据)
2. 可用性(Availability) (每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据)
3. 分区容忍(Partition tolerance) 系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择

理解CAP理论的最简单方式是：节点组成的网络，因为故障，形成互不相通的区域，即分区P, 此时要在C与A之间做权衡：
1. CP: 保证C 一致性，各个分区不可以写数据，失去的可用性A。 一般使用严格的法定数协议 (paxos, raft, zab)或者2PC协仪。有 MongoDB， HBase， Zookeeper等
1. AP: 保证A 可用性，各个分区可以写数据，失去的一致性C. 有 Couch DB，Cassandra，Amazon Dynamo等

## 事务ACID
原子性(Atomicity)
一致性(Consistency)
隔离性(Isolation)
持久性 (Durable)

## 一致性协议
todo参考:
https://zhuanlan.zhihu.com/p/25933039
https://juejin.im/post/5aa3c7736fb9a028bb189bca
https://juejin.im/post/5b5a0bf9f265da0f6523913b

### 二阶段提交( Two-phaseCommit )
当一个事务跨多个节点时， 为了让参与者知道别的节点是否成功，就引入了协调者:
参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作

1. prepare阶段：事务协调者给每个参与者发送 Prepare 消息，参与者受到消息后，要么写redo/undo日志成功后返回同意的消息，要么返回终止事务的消息。
2. 执行提交：协调者在收到所有参与者的消息后，如果有一个返回终止事务，那么协调者给每个参与者发送回滚的指令。否者发送 commit 消息

#### 缺点
执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。
参与者发生故障。协调者需要给每个参与者额外指定超时机制，超时后整个事务失败。（没有多少容错机制）
协调者发生故障。参与者会一直阻塞下去。需要额外的备机进行容错。（这个可以依赖后面要讲的Paxos协议实现HA）
二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了(不会返回success/fail rollback)。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。

作者：大闲人柴毛毛
链接：https://juejin.im/post/5aa3c7736fb9a028bb189bca

#### 异常情况处理
协调者故障：备用协调者接管，并查询参与者执行到什么地址
参与者故障：协调者会等待他重启然后执行
协调者和参与者同时故障：协调者故障，然后参与者也故障。例如：有机器 1，2，3，4。其中 4 是协调者，1，2，3是参与者 4 给1，2 发完提交事务后故障了，正好3这个时候也故障了，注意这是 3 是没有提交事务数据的。在备用协调者启动了，去询问参与者，由于3死掉了，一直不知道它处于什么状态（接受了提交事务，还是反馈了能执行还是不能执行 3 个状态）。
新协调者接管，也是一个懵逼的状态，不知道此条事务的状态。无论提交或者回滚都是不合适的。面对这种情况，2PC，是不能解决的，要解决需要下文介绍的 3PC。


### 三阶段提交协议（3PC）
3PC 就是对 2PC 漏洞的补充协议。主要改动两点： 
2. 引入超时机制。同时在协调者和参与者中都引入超时机制。
3. 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。

3PC:
1. 事务询问阶段（ can commit 阶段)：协调者向参与者发送 commit 请求，然后等待参与者反应。这个和 2PC 阶段不同的是，此时参与者没有锁定资源，没有写 redo，undo，执行回滚日志。回滚代价低
2. 事务Prepare阶段 （pre commit）：如果参与者都返回ok，那么就发送Prepare消息，参与者本地执行redo和undo日志。否者就向参与者提交终止（abort）事务的请求。如果再发送Prepare消息的时候，等待超时，也会向参与者提交终止事务的请求。
3. 执行事务阶段（do commit）：如果所有发送Prepare都返回成功，那么此时变为执行事务阶段，向参与者发送commit事务的消息。否者回滚事务。在此阶段参与者如果在一定时间内没有收到docommit消息，触发超时机制，会自己提交事务。`此番处理的逻辑是，能够进入此阶段，说明在事务询问阶段所有节点都是好的。即使在提交的时候部分失败，有理由相信，此时大部分节点都是好的。是可以提交的`

#### 缺点: 分区不一致
不能解决网络分区的导致的数据不一致的问题：例如 1~5 五个参与者节点，1，2，3 个节点在A机房，4，5 节点在 B 机房。在 pre commit阶段，1~5 个节点都收到 Prepare 消息，但是节点1执行失败。协调者向1~5个节点发送回滚事务的消息。但是此时A，B机房的网络分区。1~3 号节点会回滚。但是 4~5 节点由于没收到回滚事务的消息，而提交了事务。待网络分区恢复后，会出现数据不一致的情况。

## Paxos & Raft 
来源： [S 先生@喔家ArchiSelf][CAP理论与分布式系统设计]( https://mp.weixin.qq.com/s?__biz=MzAwOTcyNzA0OQ==&mid=2658972342&idx=1&sn=e613eff26d6ffccf0641510aae0a4acb)
![](/img/arch/arch-cap-proto.png)

2PC/3PC 引入的协调者有单点问题，无法应对分区问题。这时不得不提到Paxos了

1. Paxos 论证了自治性的一致性协议的可行性，但是paxos实现比较复杂，只有zk实现了zab协议。
2. Raft 则是对Paxos做的精简的分布式一致性复制协议。

Raft 图解
http://raftconsensus.github.io/
http://thesecretlivesofdata.com/raft/?from=timeline
