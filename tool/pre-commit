#!/usr/bin/env python3
# This script is used to generate rss atom.xml
# Usage1: 
#   ./tool/pre-commit post/java/java-inject.md post/go/go-generic.md ...
# Usage2: 
#   git add post/java/java-inject.md post/go/go-generic.md ...
#   ./tool/pre-commit -a 
import sys
import os
import re
from subprocess import getoutput
from datetime import datetime
from collections import OrderedDict
from glob import glob

XML_BASE='https://ahuigo.github.io'
USERNAME = 'Ahuigo'
PAGE_BASE="/b"

print("Exec python:",sys.executable)
print("current_path:", os.getcwd())

log = print

def breakout(*args):
    log(*args)
    quit(1)


def basename(path):
    filename = os.path.split(path)[1]
    return os.path.splitext(filename)[0]


# via: /post/c/c-shell.md
def getPostUrl(path):
    return f"{PAGE_BASE}/{path[6:-3]}"


def updateAtom(blogs, max_items=40):
    from copy import copy
    from bs4 import BeautifulSoup as BS

    atomPath = f"{getRoot()}/atom.xml"
    if os.path.exists(atomPath):
        s = open(atomPath).read()
    else:
        s = f"""
<feed xmlns="http://www.w3.org/2005/Atom">
<title>{USERNAME} 的笔记</title>
<link href="{XML_BASE}/atom.xml" rel="self" type="application/atom+xml"/>
<updated>2018-08-17T13:46:49Z</updated>
<subtitle>{USERNAME}'s notes</subtitle>
<entry xml:base="{XML_BASE}">
<title>vue instance</title>
<link href="/b/ria/vue-ins" rel="alternate" type="text/html"/>
<updated>2018-09-30T20:29:15Z</updated>
<summary/>
<published/>
<content/>
</entry></feed>
        """
    bs = BS(s, "lxml-xml")
    bs.updated.string = datetime.now().replace(microsecond=0).isoformat() + "Z"
    ori_entry = copy(bs.entry)
    ori_entry.content.string = ""

    # update
    for path, blog in blogs.items():
        href = getPostUrl(path)
        if bs.find("link", href=href):
            entry = bs.find("link", href=href).parent
        else:
            entry = copy(ori_entry)
            entry.link["href"] = href
            bs.entry.insert_before(entry)

        entry.title.string = blog["title"]
        entry.content.string = blog["content"][:100]
        entry.published.string = (
            datetime.strptime(blog["date"], "%Y-%m-%d")
            .replace(microsecond=0)
            .isoformat()
            + "Z"
        )
        entry.updated.string = (
            datetime.strptime(blog["updated"], "%Y-%m-%d")
            .replace(microsecond=0)
            .isoformat()
            + "Z"
        )

    # clear
    l = len(bs.feed.findChildren("entry"))
    if l > max_items:
        for i in bs.feed.findChildren("entry")[max_items:]:
            i.extract()

    open(atomPath, "wb").write(bs.encode())



current_date = datetime.now().strftime("%Y-%m-%d")


def parseBlog(path, withContent=False):
    blog = {"path": path}
    filePath = getRoot()+'/'+path
    print('generate rss:', filePath)
    if withContent:
        data = open(filePath).read()
    else:
        data = open(filePath).read(200)
    if data.startswith("---\n"):
        pos = data.index("\n---\n", 4)
        blogStr = data[4:pos]
        data = data[pos + 5 :]
        for line in blogStr.split("\n"):
            k, v = line.split(":", 1)
            blog[k] = v.strip()
    if "title" not in blog:
        blog["title"] = data.split("\n", 1)[0][2:].strip()
    if not blog["title"]:
        quit(f"{path} has no title")
    if "date" not in blog:
        blog["date"] = current_date
    blog["content"] = data
    blog["updated"] = current_date
    return blog

def getChangedPaths():
    cmd = 'git diff-index --cached --name-status --diff-filter=ACMR HEAD | grep -E "\spost/.+.md$" '
    out = getoutput(cmd).strip()
    paths = []
    if out:
        paths = [line.split('\t')[1].strip() for line in out.split('\n')]
    return paths

ROOT=''
def getRoot():
    global ROOT
    if not ROOT:
        cmd = 'git rev-parse --show-toplevel'
        ROOT = getoutput(cmd).strip()
    return ROOT

def chroot():
    os.chdir(getRoot())
    print(os.getcwd())

def generateRss():
    paths = sys.argv[1:]
    if '-a' in sys.argv:
        chroot()
        paths = getChangedPaths()
    new_blogs = {path: parseBlog(path) for path in paths}
    updateAtom(new_blogs)


if __name__ == '__main__':
    generateRss()

quit(1)
if os.path.exists("no-commit"):
    log("no-commit")
    quit(1)
